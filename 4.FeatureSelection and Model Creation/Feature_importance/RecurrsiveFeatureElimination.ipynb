{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b09419-464a-42bb-ba8d-db726419cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4edccc-1026-43a1-bc37-009513934f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"preprocessedEmployee.csv\", index_col=None)\n",
    "df2 = dataset\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56212e3a-9c0e-433b-be6d-1b17baa90368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Years_At_Company', 'Performance_Score', 'Monthly_Salary',\n",
       "       'Work_Hours_Per_Week', 'Projects_Handled', 'Promotions', 'Department',\n",
       "       'Gender', 'Job_Title', 'Education_Level', 'Resigned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b228bdea-d096-499d-833b-9f8179a1603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset1=pd.read_csv(\"preprocessedEmployee.csv\",index_col=None)\n",
    "df2=dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67533411-a880-4a75-918f-95d9a16c48a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Years_At_Company</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Monthly_Salary</th>\n",
       "      <th>Work_Hours_Per_Week</th>\n",
       "      <th>Projects_Handled</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>Resigned</th>\n",
       "      <th>Department_Engineering</th>\n",
       "      <th>Department_Finance</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender_Other</th>\n",
       "      <th>Job_Title_Consultant</th>\n",
       "      <th>Job_Title_Developer</th>\n",
       "      <th>Job_Title_Engineer</th>\n",
       "      <th>Job_Title_Manager</th>\n",
       "      <th>Job_Title_Specialist</th>\n",
       "      <th>Job_Title_Technician</th>\n",
       "      <th>Education_Level_High School</th>\n",
       "      <th>Education_Level_Master</th>\n",
       "      <th>Education_Level_PhD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6750</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5850</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4900</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7150</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Years_At_Company  Performance_Score  Monthly_Salary  \\\n",
       "0     55                 2                5.0            6750   \n",
       "1     29                 0                5.0            7500   \n",
       "2     55                 8                3.0            5850   \n",
       "3     48                 7                2.0            4800   \n",
       "4     36                 3                2.0            4800   \n",
       "..   ...               ...                ...             ...   \n",
       "244   45                 4                5.0            9000   \n",
       "245   32                 2                4.0            6300   \n",
       "246   24                 7                4.0            4900   \n",
       "247   43                 3                2.0            4800   \n",
       "248   32                 2                3.0            7150   \n",
       "\n",
       "     Work_Hours_Per_Week  Projects_Handled  Promotions  Resigned  \\\n",
       "0                     33                32           0     False   \n",
       "1                     34                34           2     False   \n",
       "2                     37                27           0     False   \n",
       "3                     52                10           1     False   \n",
       "4                     38                11           1     False   \n",
       "..                   ...               ...         ...       ...   \n",
       "244                   48                 9           1     False   \n",
       "245                   55                46           2     False   \n",
       "246                   30                33           0     False   \n",
       "247                   57                36           1     False   \n",
       "248                   35                43           0     False   \n",
       "\n",
       "     Department_Engineering  Department_Finance  ...  Gender_Other  \\\n",
       "0                         0                   0  ...             0   \n",
       "1                         0                   1  ...             0   \n",
       "2                         0                   1  ...             0   \n",
       "3                         0                   0  ...             0   \n",
       "4                         1                   0  ...             0   \n",
       "..                      ...                 ...  ...           ...   \n",
       "244                       0                   0  ...             0   \n",
       "245                       0                   0  ...             0   \n",
       "246                       0                   0  ...             0   \n",
       "247                       0                   0  ...             0   \n",
       "248                       0                   0  ...             0   \n",
       "\n",
       "     Job_Title_Consultant  Job_Title_Developer  Job_Title_Engineer  \\\n",
       "0                       0                    0                   0   \n",
       "1                       0                    1                   0   \n",
       "2                       0                    0                   0   \n",
       "3                       0                    0                   0   \n",
       "4                       0                    0                   0   \n",
       "..                    ...                  ...                 ...   \n",
       "244                     0                    0                   0   \n",
       "245                     0                    0                   0   \n",
       "246                     0                    0                   0   \n",
       "247                     0                    0                   0   \n",
       "248                     1                    0                   0   \n",
       "\n",
       "     Job_Title_Manager  Job_Title_Specialist  Job_Title_Technician  \\\n",
       "0                    0                     1                     0   \n",
       "1                    0                     0                     0   \n",
       "2                    0                     1                     0   \n",
       "3                    0                     0                     0   \n",
       "4                    0                     0                     0   \n",
       "..                 ...                   ...                   ...   \n",
       "244                  1                     0                     0   \n",
       "245                  0                     1                     0   \n",
       "246                  0                     0                     1   \n",
       "247                  0                     0                     0   \n",
       "248                  0                     0                     0   \n",
       "\n",
       "     Education_Level_High School  Education_Level_Master  Education_Level_PhD  \n",
       "0                              1                       0                    0  \n",
       "1                              1                       0                    0  \n",
       "2                              1                       0                    0  \n",
       "3                              0                       0                    0  \n",
       "4                              0                       0                    0  \n",
       "..                           ...                     ...                  ...  \n",
       "244                            0                       0                    0  \n",
       "245                            0                       0                    0  \n",
       "246                            0                       0                    0  \n",
       "247                            0                       0                    0  \n",
       "248                            1                       0                    0  \n",
       "\n",
       "[249 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94153cbe-5800-4528-bddc-5030daf06c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"preprocessedEmployee.csv\",index_col=None)\n",
    "df2=dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True, dtype=int)\n",
    "\n",
    "indep_X=df2.drop('Resigned', axis=1)\n",
    "dep_Y=df2['Resigned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3d0bff7-6178-4a5c-a242-9f95dd4d2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82106a03-7c38-4735-a6a5-999e895d4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_prediction(regressor,X_test,y_test):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99ec1b7b-e489-452a-a714-6286f1af7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(X_train,y_train,X_test):       \n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83350738-5f4a-47fc-9e39-01eb723424d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(X_train,y_train,X_test):\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        regressor = DecisionTreeRegressor(random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e18215d-f8d5-4bba-b670-42cd94376aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(X_train,y_train,X_test):       \n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a521fbde-f2d0-477a-94e5-936f17314875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(X_train,y_train,X_test):       \n",
    "        from xgboost import XGBRegressor\n",
    "        regressor = XGBRegressor(n_jobs=5,learning_rate=0.1,max_depth=10,random_state=1)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed2297a7-c4eb-40e1-aeee-f700a3d8e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(X_train, y_train, X_test):       \n",
    "    from sklearn.linear_model import LogisticRegression  # Changed to LogisticRegression\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def Decision(X_train, y_train, X_test):\n",
    "    from sklearn.tree import DecisionTreeClassifier  # Changed to DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def random(X_train, y_train, X_test):       \n",
    "    from sklearn.ensemble import RandomForestClassifier  # Changed to RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "def xgboost(X_train, y_train, X_test):       \n",
    "    from xgboost import XGBClassifier  # Changed to XGBClassifier\n",
    "    classifier = XGBClassifier(n_jobs=5, learning_rate=0.1, max_depth=10, random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "592a5fa3-a0dd-493e-a1b4-daccd908a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear\n",
      "Selected Columns: ['Department_Finance', 'Department_IT', 'Department_Legal', 'Education_Level_High School', 'Education_Level_Master']\n",
      "Accuracy Value: 0.9047619047619048\n",
      "\n",
      "Model: Decision\n",
      "Selected Columns: ['Age', 'Years_At_Company', 'Monthly_Salary', 'Work_Hours_Per_Week', 'Projects_Handled']\n",
      "Accuracy Value: 0.7619047619047619\n",
      "\n",
      "Model: Random\n",
      "Selected Columns: ['Age', 'Years_At_Company', 'Monthly_Salary', 'Work_Hours_Per_Week', 'Projects_Handled']\n",
      "Accuracy Value: 0.873015873015873\n",
      "\n",
      "Model: XGBoost\n",
      "Selected Columns: ['Monthly_Salary', 'Promotions', 'Department_Legal', 'Job_Title_Specialist', 'Education_Level_High School']\n",
      "Accuracy Value: 0.9047619047619048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    rfelist = []\n",
    "    colnames_list = []  \n",
    "    accuracy_values = []  # Changed from r2_values to accuracy_values\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression  # Changed to LogisticRegression\n",
    "    lin = LogisticRegression(random_state=0)\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier  # Changed to DecisionTreeClassifier\n",
    "    dec = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier  # Changed to RandomForestClassifier\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "    from xgboost import XGBClassifier  # Changed to XGBClassifier\n",
    "    xgb = XGBClassifier(n_jobs=5, learning_rate=0.1, max_depth=10, random_state=1)\n",
    "\n",
    "    rfemodellist = [lin, dec, rf, xgb]\n",
    "\n",
    "    for model in rfemodellist:\n",
    "        log_rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "        log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "        log_rfe_feature = log_fit.transform(indep_X)\n",
    "        rfelist.append(log_rfe_feature)\n",
    "\n",
    "        # Get the column names selected by RFE\n",
    "        selected_columns = [col for col, selected in zip(indep_X.columns, log_rfe.support_) if selected]\n",
    "        colnames_list.append(selected_columns)\n",
    "\n",
    "        # Fit the model and calculate accuracy\n",
    "        X_train, X_test, y_train, y_test = split_scalar(pd.DataFrame(log_rfe_feature), dep_Y)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy = accuracy_prediction(model, X_test, y_test)  # Changed from r2_prediction to accuracy_prediction\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "    return rfelist, colnames_list, accuracy_values\n",
    "\n",
    "# Call the function with your data\n",
    "rfelist, colnames_list, accuracy_values = rfeFeature(indep_X, dep_Y, 5)\n",
    "\n",
    "# Print the selected column names and accuracy values for each model\n",
    "for model_name, selected_columns, accuracy_value in zip([\"Linear\", \"Decision\", \"Random\", \"XGBoost\"], colnames_list, accuracy_values):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Selected Columns:\", selected_columns)\n",
    "    print(f\"Accuracy Value: {accuracy_value}\\n\")  # Changed from R2 Value to Accuracy Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca54ed70-c134-4bb6-bff3-87c75bae0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_prediction(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27abe604-0a86-4494-a42f-f3499663c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.5-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/56.8 MB 16.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 4.5/56.8 MB 20.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 5.2/56.8 MB 11.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.0/56.8 MB 8.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 6.3/56.8 MB 7.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 7.1/56.8 MB 6.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 7.9/56.8 MB 6.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 8.7/56.8 MB 5.8 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 9.2/56.8 MB 5.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 9.2/56.8 MB 5.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 9.4/56.8 MB 4.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 9.7/56.8 MB 4.2 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 9.7/56.8 MB 4.2 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 10.0/56.8 MB 3.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 10.2/56.8 MB 3.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 10.2/56.8 MB 3.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 10.5/56.8 MB 3.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 10.5/56.8 MB 3.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 10.5/56.8 MB 3.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 10.7/56.8 MB 2.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 11.0/56.8 MB 2.5 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 11.0/56.8 MB 2.5 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 11.3/56.8 MB 2.5 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 11.5/56.8 MB 2.4 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 11.8/56.8 MB 2.3 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 12.1/56.8 MB 2.3 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 12.3/56.8 MB 2.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 12.6/56.8 MB 2.2 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 13.1/56.8 MB 2.2 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 13.4/56.8 MB 2.1 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 13.6/56.8 MB 2.1 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 14.2/56.8 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 14.4/56.8 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 14.9/56.8 MB 2.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 15.5/56.8 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 16.3/56.8 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 16.8/56.8 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 17.3/56.8 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 17.8/56.8 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 18.4/56.8 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 18.9/56.8 MB 2.2 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 19.4/56.8 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 19.9/56.8 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 20.4/56.8 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 21.2/56.8 MB 2.2 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 21.8/56.8 MB 2.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 22.5/56.8 MB 2.2 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 23.3/56.8 MB 2.3 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 23.9/56.8 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 24.6/56.8 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 25.4/56.8 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 26.0/56.8 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 26.7/56.8 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 27.5/56.8 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 28.3/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 28.8/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 29.1/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 29.4/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 29.6/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 29.9/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 29.9/56.8 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.1/56.8 MB 2.3 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.1/56.8 MB 2.3 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.1/56.8 MB 2.3 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.4/56.8 MB 2.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.4/56.8 MB 2.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 30.7/56.8 MB 2.2 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 30.7/56.8 MB 2.2 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 30.7/56.8 MB 2.2 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 30.9/56.8 MB 2.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 30.9/56.8 MB 2.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 30.9/56.8 MB 2.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 31.2/56.8 MB 2.0 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 31.2/56.8 MB 2.0 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 31.5/56.8 MB 2.0 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 31.5/56.8 MB 2.0 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 31.7/56.8 MB 1.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 31.7/56.8 MB 1.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 32.0/56.8 MB 1.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 32.0/56.8 MB 1.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 32.2/56.8 MB 1.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.2/56.8 MB 1.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 32.8/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 33.0/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 33.3/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 33.6/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 34.1/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 34.6/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 34.9/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 35.1/56.8 MB 1.8 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 35.7/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 35.9/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 36.4/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 36.7/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 37.2/56.8 MB 1.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 37.7/56.8 MB 1.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 38.3/56.8 MB 1.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 38.8/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 39.3/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 39.8/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 40.1/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 40.4/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 40.4/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 40.6/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 40.9/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 40.9/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 41.2/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 41.2/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.4/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.4/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.7/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.7/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.9/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.9/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.9/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 42.2/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 42.2/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 42.5/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 42.5/56.8 MB 1.7 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 42.7/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 42.7/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 42.7/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 43.0/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 43.0/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 43.3/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 43.5/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 43.8/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 44.3/56.8 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 44.6/56.8 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 44.8/56.8 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 45.1/56.8 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 45.4/56.8 MB 1.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 45.9/56.8 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 46.1/56.8 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 46.7/56.8 MB 1.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 47.2/56.8 MB 1.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 47.4/56.8 MB 1.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.7/56.8 MB 1.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 48.2/56.8 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 48.8/56.8 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 49.3/56.8 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 49.5/56.8 MB 1.5 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 50.1/56.8 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 50.6/56.8 MB 1.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 51.4/56.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 51.9/56.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 52.4/56.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 52.4/56.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 52.7/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.0/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.0/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.2/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.2/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.7/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.7/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.7/56.8 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 54.0/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.0/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.0/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.3/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.3/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.5/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.5/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.8/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.8/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.8/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 55.1/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 55.1/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 55.3/56.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  55.6/56.8 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.8/56.8 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.1/56.8 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.4/56.8 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "871d749c-5b1b-49a3-ac74-9e0f7365f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "The f1 macro value the best parameter{'criterion': 'gini', 'max_features': 'log2', 'splitter': 'random'}: 0.79145786755069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.74633221 0.76093129 0.75931128 0.74721192\n",
      "        nan        nan 0.7267833  0.75735905 0.7510554  0.74538878\n",
      "        nan        nan 0.75192896 0.7644759  0.72374012 0.76949375]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import pickle\n",
    "\n",
    "# Now you can use rfelist and colnames_list to train the Decision Tree model with the selected features\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(rfelist[1], dep_Y, test_size=0.25, random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'gini'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit=True, verbose=3, n_jobs=-1, scoring='f1_weighted')\n",
    "grid.fit(X_train, y_train)\n",
    "re=grid.cv_results_\n",
    "y_predict=grid.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_predict)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test,y_predict)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_predict,average='weighted')\n",
    "print(\"The f1 macro value the best parameter{}:\".format(grid.best_params_),f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0811296f-3925-4c52-92d1-531f431acff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47 10]\n",
      " [ 5  1]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4acfd-24e9-42f2-ab8f-02dfaea4059d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd682c-5c19-489f-8d8e-9f5ed6f2761a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2febaed-bb2c-431e-aacf-8fef4e63fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:134: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Logistic'][idex]=acclog[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:135: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:136: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMnl'][idex]=accsvmnl[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:137: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['KNN'][idex]=accknn[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:138: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Navie'][idex]=accnav[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:139: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\sindhiya maria\\AppData\\Local\\Temp\\ipykernel_15848\\491892025.py:140: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Random'][idex]=accrf[number]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic      SVMl     SVMnl       KNN     Navie  Decision    Random\n",
       "Logistic  0.904762  0.904762  0.904762  0.904762  0.857143  0.904762  0.904762\n",
       "Random    0.904762  0.904762  0.904762  0.888889  0.904762  0.777778  0.888889"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def rfeFeature(indep_X,dep_Y,n):\n",
    "        rfelist=[]\n",
    "        \n",
    "        log_model = LogisticRegression(solver='lbfgs')\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "       # NB = GaussianNB()\n",
    "        DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "        svc_model = SVC(kernel = 'linear', random_state = 0)\n",
    "        #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        rfemodellist=[log_model,RF]#svc_model,DT] \n",
    "        for i in   rfemodellist:\n",
    "            print(i)\n",
    "            log_rfe = RFE(estimator=i, n_features_to_select=n)\n",
    "            log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "            log_rfe_feature=log_fit.transform(indep_X)\n",
    "            rfelist.append(log_rfe_feature)\n",
    "        return rfelist\n",
    "    \n",
    "\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "   \n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "\n",
    "def rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    rfedataframe=pd.DataFrame(index=['Logistic','Random'],columns=['Logistic','SVMl','SVMnl',\n",
    "                                                                                        'KNN','Navie','Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(rfedataframe.index):\n",
    "        \n",
    "        rfedataframe['Logistic'][idex]=acclog[number]       \n",
    "        rfedataframe['SVMl'][idex]=accsvml[number]\n",
    "        rfedataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        rfedataframe['KNN'][idex]=accknn[number]\n",
    "        rfedataframe['Navie'][idex]=accnav[number]\n",
    "        rfedataframe['Decision'][idex]=accdes[number]\n",
    "        rfedataframe['Random'][idex]=accrf[number]\n",
    "    return rfedataframe\n",
    "\n",
    "\n",
    "\n",
    "dataset1=pd.read_csv(\"preprocessedEmployee.csv\",index_col=None)\n",
    "df2=dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True, dtype=int)\n",
    "\n",
    "indep_X=df2.drop('Resigned', axis=1)\n",
    "dep_Y=df2['Resigned']\n",
    "\n",
    "\n",
    "rfelist=rfeFeature(indep_X,dep_Y,3)       \n",
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "\n",
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n",
    "result=rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "898cf4eb-a2c1-44f8-ba68-7e572eb6b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def rfeFeature(indep_X,dep_Y,n):\n",
    "        rfelist=[]\n",
    "        \n",
    "        log_model = LogisticRegression(solver='liblinear')\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "       # NB = GaussianNB()\n",
    "        DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "        svc_model = SVC(kernel = 'linear', random_state = 0)\n",
    "        #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        rfemodellist=[log_model,RF]#svc_model,RF,DT] \n",
    "        for i in   rfemodellist:\n",
    "            print(i)\n",
    "            log_rfe = RFE(estimator=i,n_features_to_select=n)\n",
    "            log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "            log_rfe_feature=log_fit.transform(indep_X)\n",
    "            rfelist.append(log_rfe_feature)\n",
    "        return rfelist\n",
    "    \n",
    "\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "   \n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "\n",
    "def rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    rfedataframe=pd.DataFrame(index=['Logistic','SVC','Random','DecisionTree'],columns=['Logistic','SVMl','SVMnl',\n",
    "                                                                                        'KNN','Navie','Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(rfedataframe.index):\n",
    "        \n",
    "        rfedataframe['Logistic'][idex]=acclog[number]       \n",
    "        rfedataframe['SVMl'][idex]=accsvml[number]\n",
    "        rfedataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        rfedataframe['KNN'][idex]=accknn[number]\n",
    "        rfedataframe['Navie'][idex]=accnav[number]\n",
    "        rfedataframe['Decision'][idex]=accdes[number]\n",
    "        rfedataframe['Random'][idex]=accrf[number]\n",
    "    return rfedataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1668d4b-763c-406d-b3fc-63eca5fa5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
